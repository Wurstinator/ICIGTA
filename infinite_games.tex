\documentclass{article}

\usepackage{amsmath, amssymb, amsthm}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\usepackage{tikz}

\begin{document}
\section{Basics}
\subsection{List Of Games}
\begin{itemize}
	\item Büchi
	\item Staiger-Wagner
	\item weak Parity
	\item Reachability (E-condition)
	\item Safety (A-condition)
	\item Muller
	\item Parity
	\item Rabin
	\item Streett
\end{itemize}

\subsection{List Of Properties}
\begin{itemize}
	\item Determined \\
		For every node $v$, either player has a winning strategy.
	\item Positionally Determined \\
		For every node $v$, either player has a positional winning strategy.
	\item Uniform determined \\
		There are disjoint sets $W_0 \cup W_1 = V$ and strategies $\sigma_0$ and $\sigma_1$ for player 0 and 1 respectively, such that $\sigma_0$ is winning from all $v \in W_0$ and $\sigma_1$ is winning from all $v \in W_1$.
	\item Prefix Independent \\
		$\forall x \in C^*, \alpha \in C^\omega: \alpha \in \text{Win} \leftrightarrow x \alpha \in \text{Win}$
\end{itemize}

\subsection{Definitions}
\begin{definition}
	A \textbf{game graph / arena} is a tuple $G = (V_0, V_1, E, c)$ where $V_0 \cap V_1 = \emptyset$, $E \subseteq V \times V$ where $V = V_0 \cup V_1$, and $c : V \rightarrow C$ for a finite set of colors $C$.
	
	A \textbf{game} is a pair $\mathcal{G} = (G, \text{Win})$ where $G$ is an arena and $\text{Win} \subseteq C^\omega$.
	
	A \textbf{strategy} for player $i$ is a function $\sigma : V^* V_i \rightarrow V$ with $(u, v) \in E$ for all $\sigma(xu) = v$. $\sigma$ is a \textbf{winning strategy} from $v \in V$, if all plays from $v$ that are according to $\sigma$ are won by player $i$. $\sigma$ is \textbf{positional} if for all $x, y \in V^*, v \in V$: $\sigma(xv) = \sigma(yv)$.
\end{definition}

\newpage

\section{Memory \& Reductions}
\begin{definition}
	A \textbf{strategy automaton} for player 0 in a game $\mathcal{G}$ is a tuple $\mathcal{A} = (M, C, m_\text{in}, \sigma^u, \sigma^n)$ with $\sigma^n : M \times V_0 \rightarrow V$ and $\sigma^u : M \times C \rightarrow M$. The automaton defines a strategy $\sigma_\mathcal{A}(xv) = \sigma^n(m, v)$ where $m = (\sigma^u)^*(m_\text{in}, x)$.
\end{definition}

\begin{definition}
	Let $\mathcal{G}$ and $\mathcal{G}'$ be games. \textbf{$\boldsymbol{\mathcal{G}}$ reduces to $\boldsymbol{\mathcal{G}'}$ with memory $\boldsymbol{m}$} if there is an $f_\text{in} : V \rightarrow V'$ such that a player wins from $v \in V$ iff that player wins from $f_\text{in}(v) \in V'$. For a winning strategy with memory $n$ from $f_\text{in}(v)$, one can compute a winning strategy with memory $n \cdot m$ from $v$.
\end{definition}

\begin{definition}
	Let $\mathcal{G} = (V_0, V_1, E, c, \text{Win})$ be a game and let $\mathcal{A} = (Q, C, q_0, \delta, \text{Acc})$ be a finite automaton with $L(\mathcal{A}) = \text{Win}$. The \textbf{product game} is defined as $\mathcal{G} \times \mathcal{A} = (V_0', V_1', E', c', \text{Acc})$ with
	\begin{itemize}
		\item $V'_0 = V_0 \times Q$
		\item $V'_1 = V_1 \times Q$
		\item $E' = \{ ((u, p), (v, q) \in (V \times Q)^2 \mid (u,v) \in E \text{ and } q = \delta(p, c(u)) \}$
		\item $c'(v, q) = q$
	\end{itemize}
\end{definition}

\begin{theorem}
	$\mathcal{G}$ reduces to $\mathcal{G} \times \mathcal{A}$ with memory $|Q|$.
\end{theorem}
%TODO notes

\paragraph{Example}
	Let $\mathcal{A} = (Q, C, q_0, \delta, F)$ be a DFA and let $\mathcal{G} = (G, C^* L(\mathcal{A}) C^\omega)$. Then $\mathcal{G}$ is a reachability game. Hence, $\mathcal{G} \times \mathcal{A}$ is determined with memory size $|Q|$.

\newpage

\section{Prefix Dependent Games}
\subsection{Reachability \& Safety}
$F \subseteq C$ and $\text{Win} = C^* F C^\omega$ (reachability) or $\text{Win} = (C \setminus F)^\omega$ (safety)

\begin{theorem}
	Reachability games and safety games are positionally determined. The winning regions and winning strategies can be computed in $\mathcal{O}(|G|)$.
\end{theorem}
\begin{proof}
	Let $\mathcal{G} = (G, F)$ be a reachability or safety game. The \textbf{attractor} for player 0 is defined as follows:
	\begin{itemize}
		\item $\text{Pre}_0(X) = \{ v \in V_0 \mid \exists x \in X: (v, x) \in E \} \cup \{ v \in V_1 \mid \neg \exists x \in X^\complement: (v, x) \in E \}$ \\
			The set of vertices from which player 0 can force a direct move to a vertex in $X$.
		\item $\text{Attr}_0^0(X) = X$ \\
			$\text{Attr}_0^{i+1}(X) = \text{Attr}_0^i(X) \cup \text{Pre}_0(\text{Attr}_0^i(X))$ \\
			The set of vertices from which player 0 can force to reach $X$ in at most $i$ steps.
		\item $\text{Attr}_0(X) = \bigcup_{i \in \mathbb{N}} \text{Attr}_0^i$ \\
			The set of vertices from which player 0 can force a play to reach $X$.
	\end{itemize}
	
	Then $W_0 = \text{Attr}_0(F)$ for reachability games and $W_0 = V \setminus \text{Attr}_1(F^\complement)$ for safety games. The winning strategy for player 0 is to play from each $\text{Attr}^i_0$ to $\text{Attr}^{i-1}_0$ until $F$ is reached. The strategy for player 1 is to play to arbitrary nodes not in $W_0$.
	
	A simple algorithm can compute the attractor in $\mathcal{O}(|G|^2)$ but linear time is also possible.
\end{proof}

\vspace{1.5cm}
\subsection{Weak Parity}
$C \subseteq \mathbb{N}$ and $\text{Win} = \{ \alpha \in C^\omega \mid \max \text{Occ}(\alpha) \text{ is even}\}$.

\begin{theorem}
	Weak parity games are positionally determined. The winning regions and winning strategies can be computed in $\mathcal{O}(|C| \cdot |G|)$.
\end{theorem}
\begin{proof}
	If the arena is empty, then $W_0 = W_1 = \emptyset$. Otherwise let $k = \max c(V)$. Due to symmetry we can assume that $k$ is even. Let $A_k = \text{Attr}_0(c^{-1}(k))$. Compute the winning regions $(W_0, W_1)$ in the game with vertices $A_k$ removed. Then the winning regions in $\mathcal{G}$ are $(W_0 \cup A_k, W_1)$.
	
	The winning strategy for player 0 in $A_k$ is to move to that set and then play arbitrarily. From all other nodes, the induction strategy suffices.
	
	In each iteration, one color is removed and one attractor is computed, which results in the described runtime.
\end{proof}


\vspace{1.5cm}
\subsection{Staiger-Wagner}
$\mathcal{F} \subseteq 2^C$ and $\text{Win} = \{ \alpha \in C^\omega \mid \text{Occ}(\alpha) \in \mathcal{F} \}$.

\begin{theorem}
	Staiger-Wagner games can be reduced to weak parity games with memory $2^{|C|}$.
\end{theorem}
\begin{proof}
	Build a weak parity automaton with $2^{|C|}$ states that accepts $\text{Win}$ with SW condition $\mathcal{F} \subseteq 2^C$. For that, the PA collects a set of all seen colors as its state. For such a state $P \subseteq C$, the assigned color is $c(P) = \begin{cases} 2 \cdot |P| & \text{if } P \in \mathcal{F} \\ 2 \cdot |P| - 1 & \text{else} \end{cases}$.
\end{proof}

\vspace{0.5cm}
\begin{theorem}
	For every $n > 0$, there is an arena $G_n$ with $|G_n| \in \mathcal{O}(n)$ and a set $\mathcal{F}_n \subseteq 2^C$ with $|\mathcal{F}_n| \in \mathcal{O}(n)$ such that player 0 has a winning strategy in the Staiger-Wagner game $(G_n, \mathcal{F}_n)$ but every winning strategy requires memory of size $2^n$.
\end{theorem}
\begin{proof}
	The game uses colors $C_n = \{1, \dots, n, 1', \dots, n', 0\}$ and consists of two phases. First, player 1 selects for each $1 \leq i \leq n$ either $i$ or $i'$. This requires $3n$ vertices. In the second phase, player 0 has the same choices to make as player 1 before. After this, the last vertex is colored $0$ and loops to itself. This gives a total of $3n+1$ vertices. Player 0 wins iff all colors $C_n$ are seen.
	
	Player 0 has to memorize all $2^n$ possible choices that player 1 could make to answer accordingly. Otherwise there would be two different strategies from player 1 that lead to the same memory state of player 0, meaning that one leads to a losing play for player 0.
\end{proof}

\vspace{1.5cm}
\section{Prefix Independent Games}
\subsection{Büchi Games}
$F \subseteq C$ and $\text{Win} = \{ \alpha \in C^\omega \mid \text{Inf}(\alpha) \cap F \neq \emptyset \}$.

\begin{theorem}
	Büchi games are uniformly positionally determined. The winning regions and winning strategies can be computed in polynomial time in $|G|$.
\end{theorem}
\begin{proof}
	Define the set recurrence set for player 0 as follows:
	\begin{itemize}
		\item $\text{Recur}^0_0(X) = X$ \\
			$\text{Recur}^{i+1}_0(X) = R \setminus \text{Pre}_1(V \setminus \text{Attr}_0(R))$ where $R = \text{Recur}^i_0(X)$ \\
			The set of vertices in $X$ from which player 0 can force at leasts $i$ other vists to $X$.
		\item $\text{Recur}_0(X) := \bigcap_{i \in \mathbb{N}} \text{Recur}^i_0(X)$ \\
			The set of vertices in $X$ from which player 0 can force infinitely many other visits to $X$.
	\end{itemize}
	
	We write $F_i = \text{Recur}^i_0(F)$ for all $i$ and $F_\infty = \text{Recur}_0(F)$. Then $W_0 = \text{Attr}_0(F_\infty)$.
	
	 The winning strategy for player 0 is to attract towards $F_\infty$ over and over again. The winning strategy for player 1 is as follows: if the play reaches a node in $V \setminus \text{Attr}_0(F_\infty)$ then that node is in some $V \setminus \text{Attr}_0(F_i)$. The strategy avoids $F_i$. If $F$ is reached at some point, then player 1 can force the next move to go into $V \setminus \text{Attr}_0(F_j)$ for some $j < i$. Hence, $F$ is visited only finitely often.
	
	Note that in each step of $\text{Recur}$, at least one state in $F$ is removed and one attractor is computed, giving runtime $\mathcal{O}(|F| \cdot |G|)$.
\end{proof}
\begin{proof}
	An alternative proof does not compute the explicit sets $\text{Recur}^i_0(F)$ but rather computes $\mu(v) := \max \{i \mid v \in \text{Recur}^i_0(F)\}$. For that, define the bounded addition $\oplus$ on $D = \{0, \dots, |F|, \top\}$ as 
	$$x \oplus y = \begin{cases} x+y & \text{if } x \neq \top, y \neq \top, x+y \leq |F| \\ \top & \text{else} \end{cases}.$$
	
	Let $f : V \rightarrow \mathbb{N}, v \mapsto \begin{cases} 1 & \text{if } v \in F \\ 0 & \text{else} \end{cases}$ and define the functor $M : V^D \rightarrow V^D$ as
	$$ (M(g))(v) = \begin{cases}
		\max g(vE) \oplus f(v) & \text{if } v \in V_0 \\
		\min g(vE) \oplus f(v) & \text{if } v \in V_1
	\end{cases}. $$
	
	Then let $\mu_0 = f$ and $\mu_{i+1} = M(\mu_i)$. The desired function is the fixed point of this sequence, $\mu = \mu_k = \mu_{k+1}$. The winning region for player 0 is $W_0 = \mu^{-1}(\top)$. The winning strategy is to play from $v$ to that node $u$ which caused $\mu(v) = \top$.
\end{proof}

\vspace{1.5cm}
\subsection{Parity Games}
$C \subseteq \mathbb{N}$ and $\text{Win} = \{ \alpha \in C^\omega \mid \max \text{Inf}(\alpha) \text{ is even}\}$.

\begin{theorem}
	Parity games are uniformly positionally determined.
\end{theorem}
\begin{proof}
	Let $U := \{ v \in V \mid \text{Player 1 has a positional winning strategy from } v \}$ and let $k = \max C$. Wlog we assume that $k$ is even.
	
	\paragraph{Claim}: Player 1 has a uniform positional strategy that is winning from $U$.
	
	For all $u \in U$, let $\sigma_u$ be a positional winning strategy from $u$. Let $\prec$ be an arbitrary well-ordering of $U$. We define the positional strategy $\sigma$ as follows and claim that it is winning from all nodes in $U$:
	
	For $v \in U \cap V_1$, let $R := \{ u \in U \mid \text{Player 0 can reach } v \text{ from } u \text{ against } \sigma_u \}$ be the set of nodes in $U$ from which a winning play can reach $v$. We set $\sigma(v) = \sigma_u(v)$ for $u = \min_\prec R$. After finitely many steps, each play will end up using only one fixed $\sigma_u$, meaning that it is winning for player 1.
	
	\paragraph{Claim}: Player 0 has a uniform positional strategy that is winning from $V \setminus U$.
	
	Consider $A_k := \text{Attr}_0(c^{-1}(k) \setminus U)$ and $G' = G \upharpoonright_{V \setminus (U \cup A_k)}$. The sub-graph $G'$ only uses colors up to $k-1$, so we can obtain the winning regions $W'_0, W'_1$ of $G'$ with strategies $\sigma'_0, \sigma'_1$ by induction. 

	Let $R \subseteq V \setminus W'_1$ be the nodes that player 0 can reach from $W'_1$ against $\sigma'_1$. We have $R \cap W'_0 = \emptyset$ because otherwise there would be a winning strategy for player 0 in some parts of $W'_1$. Further, we have $R \cap A_k = \emptyset$ because otherwise player 0 could force to attract to $A_k$ from some parts in $W'_1$, meaning that those nodes would not be part of $G'$ in the first place. Therefore $R \subseteq U$. This however means that $\sigma'_1$ is a positional winning strategy in $G$ from $W'_1$, so $W'_1 \subseteq U$ by definition. Since also $W'_1 \subseteq V' \subseteq U^\complement$, we have $W'_1 = \emptyset$.
	
	We can now define a positional winning strategy for player 0. From $W'_0$ it suffices to play like $\sigma'_0$. From $A_k \setminus c^{-1}(k)$, the attractor strategy is played. From a node $v \in c^{-1}(k) \setminus U$, player 0 moves to any node in $U^\complement$. There must be such a node, otherwise $v$ would be in $U$ itself.
\end{proof}

\vspace{0.5cm}
\begin{theorem}
	 In parity games, the winning regions and winning strategies can be computed in non-deterministic polynomial time in $|G|$, or in deterministic time $\mathcal{O}\left(|V| \cdot |E| \cdot |C| \cdot (\frac{|V|}{|C|} + 1)^{2|C|}\right)$.
\end{theorem}
\begin{proof}
	The problem is in NP and co-NP. One can guess a strategy for player 0 or 1 and then verify that it is winning/losing in polynomial time.
	
	Let $\sigma : V_0 \rightarrow V$ be a positional strategy for player 0. The following procedure checks whether $\sigma$ is winning in $\mathcal{G}$ from a node $v_0$. Consider the graph $G'$ which restricts edges from vertices in $V_0$ to those used by $\sigma$. Compute the strongly connected components that contain loops and are reachable from $v_0$. If the maximal priority in the SCCs is odd, then $\sigma$ is not a winning strategy. Otherwise, remove all nodes with that priority and repeat the procedure.
\end{proof}
\begin{proof}
	An inductive algorithm works as follows. 
	\begin{enumerate}
		\item Set $i = 0$, $F^0_k = F$, and $G_i = G$.
		\item Let $A^i = \text{Attr}_0(F^i_k)$ in $G$.
		\item Let $(W^i_0, W^i_1)$ be the winning regions in $G_i \setminus A^i$ by induction.
		\item Let $B_i = \text{Attr}_1(W^i_1)$ in $G$.
		\item Let $G_{i+1} := G_i \setminus B_i$ and $F^{i+1}_k = F^i_k \setminus B_i$.
		\item Increment $i$ and go to step 2.
	\end{enumerate}
	Let $i = \infty$ be the index at which there is no more change. Then $W_0 = W^\infty_0 \cup A^\infty$. The winning strategy for player 0 is to play like the induction strategy in $W^\infty_0$ if possible and otherwise move to $F_k$ and stay in $W_0$. The winning strategy for player 1 is to move towards the $W^i_1$ with minimal $i$.
\end{proof}
\begin{proof}
	A final algorithm uses a similar approach uses \textbf{small progress measures}. Let $C = \{0, \dots, 2k\}$ and $D \subseteq \{ 0, \dots, |V| \}^k$ be a domain of vectors such that component $0 \leq i < k$ ranges from $0$ to $|c^{-1}(2i+1)|$ and let $D_\perp = D \cup \{\perp\}$. We define bounded addition $\oplus$ of an element from $D_\perp$ with a color $p$ as follows:
	
	For $\perp$, we have $\perp \oplus p = \perp$. Otherwise, let $(a_1, \dots, a_k) \in D$. Let $(b_1, \dots, b_k)$ be such that: $b_j = 0$ for all $j < \lfloor \frac{p}{2} \rfloor$. The rest of the vector corresponds to addition by 1 with carry-over if a component exceeds its value. If $b_k$ is within its bounds, let $\overline{a} \oplus p = \overline{b}$; otherwise we set $\overline{a} \oplus p = \perp$.
	
	Define the functor $M : V^{D_\perp} \rightarrow V^{D_\perp}$ as
	$$ (M(g))(v) = \begin{cases}
		\min g(vE) \oplus c(v) & \text{if } v \in V_0 \\
		\max g(vE) \oplus c(v) & \text{if } v \in V_1
	\end{cases}. $$
	
	Let $\mu_0(v) = \overline{0} \oplus c(v)$ and $\mu_{i+1} = M(\mu_i)$. The desired function is the fixed point of this sequence, $\mu = \mu_k = \mu_{k+1}$. The winning region for player 1 is $W_0 = \mu^{-1}(\perp)$. 
	
	Required time is $\mathcal{O}\left(|E| \cdot |V| \cdot |C| \cdot (\frac{|V|}{|C|} + 1)^{|C|}\right)$.
\end{proof}

\vspace{1.5cm}
\subsection{Muller Games}
$\mathcal{F} \subseteq 2^C$ and $\text{Win} = \{ \alpha \in C^\omega \mid \text{Inf}(\alpha) \in \mathcal{F} \}$.

\begin{theorem}
	Muller games can be reduced to parity games with memory $|C| \cdot |C|!$.
\end{theorem}
\begin{proof}
	A Muller automaton can be transformed to a DPA using the LAR construction.
\end{proof}

\vspace{0.5cm}
\begin{theorem}
	For every $n > 0$, there is an arena $G_n$ with $|G_n| \in \mathcal{O}(n)$ and a set $\mathcal{F}_n \subseteq 2^C$ such that player 0 has a winning strategy in the Muller game $(G_n, \mathcal{F}_n)$ but every winning strategy requires memory of size $n!$.
\end{theorem}
\begin{proof}
	The game works as follows: the two players take turns in alternation. Player 1 picks a node from $X = \{x_1, \dots, x_n\}$. After that, player 0 picks a node from $Y = \{y_1, \dots, y_n\}$. A play $\pi$ with $\text{Inf}(\pi) = F$ is winning for player 0 iff $|X \cap F| = \max \{ i \mid y_i \in F \}$. In other words, player 0 has to decide exactly how many different values player 1 chooses infinitely often.
	
	Player 0 has a uniform winning strategy from every node. Using a LAR memory automaton, for a LAR state $[x_{i_1}, \dots, x_{i_n}, h]$, player 0 picks $y_h$. Now let $\mathcal{M} = (M, C, m_0, \sigma^u, \sigma^n)$ be an arbitrary memory automaton that defines a winning strategy for player 0. It remains to be shown that $|M| \geq n!$. We prove that $M$ has an SCC with at least $n!$ states from which no other SCC is reachable.
	
	If $n = 1$, this is trivial. For $n > 1$, we can assume that $m_0$ is in such a final SCC since Muller games are prefix independent. Moreover we can simply assume that $\mathcal{M}$ only consists of a single SCC. For every $i$, there must be a state $m_i \in M$ such that from $m_i$, if player 1 never plays $x_i$, player 0 never plays $y_n$. If this would not be the case, then player 1 could use at most $n-1$ different colors to force player 0 to play $y_n$ infinitely often, making $\sigma_\mathcal{M}$ a non-winning strategy. 
	
	For all $i$, let $\mathcal{M}_i = (M_i, C, m_i, \sigma^u \upharpoonright_{M_i}, \sigma^n \upharpoonright_{M_i})$ with $M_i = M \setminus \{x_i, y_n\}$. This memory automaton defines a winning strategy for player 0 win the game $\mathcal{G}_n^i$, which is obtained from $\mathcal{G}_n$ by removing $x_i$ and $y_n$. This game is isomorphic to $\mathcal{G}_{n-1}$, so $\mathcal{M}_i$ has a final SCC of size at least $(n-1)!$. We call this SCC $S_i \subseteq M_i \subseteq M$. Hence, $|M| \geq |\bigcup_{i=0}^n S_i|$. If we can show that all $S_i$ are disjoint, then $|M| \geq \bigcup_{i=0}^n |S_i| = n \cdot (n-1)! = n!$.
	
	Assume that there are $i, j$ and $m$ such that $m \in S_i \cap S_j$. We can then define a strategy $\sigma$ for player 1that wins against $\mathcal{M}$, leading to a contradiction. Player 1 first plays so that the memory automaton reaches $m$. $S_i$ is a final SCC in $\mathcal{M}_i$, so player 1 can play all nodes $X \setminus \{x_i\}$ followed by a word in $(X \setminus \{x_i\})^*$ such that the memory automaton reaches $m$ again. After that, player 1 can play $X \setminus \{x_j\}$ and reach $m$ again. Repeating these two runs makes player 1 reach all nodes in $X$ infinitely often. However, player 0 never picks $y_n$ by definition of $S_i$ and $S_j$.
\end{proof}

\vspace{0.5cm}
\begin{theorem}
	Let $(G, \mathcal{F})$ be a finite Muller game. Player 0 and player 1 have uniform winning strategies from their respective winning regions of size at most $m^0_\mathcal{F}$ / $m^1_\mathcal{F}$. (the automata use $V$ for the update function instead of $C$)
\end{theorem}
\begin{proof}
	Due to symmetry we can assume that $C \in \mathcal{F}$. Let $\mathcal{S}_{\mathcal{F}_1}, \dots, \mathcal{S}_{\mathcal{F}_n}$ with color sets $D_1, \dots, D_n$ be the direct subtrees of $\mathcal{S}_\mathcal{F}$. Let $U_i = c^{-1}(C \setminus D_i)$ and $\mathcal{G}_i = (G \setminus \text{Attr}_0(U_i), \mathcal{F}_i)$. Using induction on the size of the arena gives us winning regions $W_0^i, W_1^i$ in $\mathcal{G}_i$ with winning strategies $\sigma_0^i, \sigma_1^i$.
	
	First, consider the case that $W_1^i = \emptyset$ for all $i$. Then player 0 wins on the entire graph. Player 0 keeps track of one fixed $i$ at all times. On $W_0^i$, they can simply play by $\sigma^i_0$. On $\text{Attr}_0(U_i)$, they attract $U_i$, after which they move their state to the next $i$. 
	
	An infinite play of this strategy either stays in some $W_0^i$ from some point on or visits every $U_i$ infinitely often. In the latter case, the infinity set $I \subseteq C$ is not a subset of any $D_i$, meaning that $I \in \mathcal{F}$. Since the strategy needs to include all winning strategies $\sigma_0^i$, the memory is the summed size.
	
	For the second case, let $J = \{ j \in \{1, \dots, n\} \mid W^j_1 \neq \emptyset \}$ and define $\hat{\mathcal{G}} = (G \setminus \text{Attr}_1(\mathcal{W}), \mathcal{F})$ with $\mathcal{W} = \bigcup_{j \in J} W^1_j$. The game $\hat{\mathcal{G}}$ can be solved with the previous case, giving winning regions $\hat{W_0}, \hat{W_1}$ with strategies $\hat{\sigma_0}, \hat{\sigma_1}$. Player 0 can win on $\hat{W_0}$ with $\hat{\sigma_0}$. On the rest of the graph, player 1 wins.
	
	In $\hat{W_1}$, player 1 can play according to $\hat{\sigma_1}$. On $\text{Attr}_1(\mathcal{W})$, player 1 attracts to some $W^1_j$ from which he plays $\sigma^1_j$ to win. Since player 1 only uses a positional attractor strategy until they reach $\hat{W_1}$ or some $W^1_j$, the memory required for this strategy is the maximal memory in $\hat{\sigma_1}$ and all $\sigma^1_j$.
\end{proof}

\vspace{0.5cm}
\begin{theorem}
	For every $\mathcal{F} \subseteq 2^C$, there is an arena $G_\mathcal{F}$ such that player 0 wins $(G_\mathcal{F}, \mathcal{F})$ but every winning strategy requires memory at least $m^0_\mathcal{F}$.
\end{theorem}
\begin{proof}
	Due to symmetry we can assume that $C \in \mathcal{F}$.	We define the game $G_\mathcal{F}$ in which player 0 requires $m^0_\mathcal{F}$ memory to win. Let $\mathcal{S}'$ be constructed from $\mathcal{S}_\mathcal{F}$ by keeping only one child with the highest $m_0$ for all 1-nodes. This means that $\mathcal{S}'$ has exactly $m^0_\mathcal{F}$ many leaves; let those leaves be called $x_1, \dots, x_{m^0_\mathcal{F}}$ in arbitrary order. Further, let $Y = \{y_1, \dots, y_l\}$ be the set of non-leaf 0-nodes.
	
	The game works as follows: player 0 picks any leaf $x_i$, followed by player 1 picking a $y_j$ that is an ancestor of $x_i$. Let $y_k$ be the next node in $Y$ from $y_j$ to $x_i$. Player 1 again then chooses a color in $C_{y_j}$ and color in $C_{y_j} \setminus C_{y_k}$. After this, the turn begins anew. Player 0 wins iff $\text{Inf}(\pi) \in \mathcal{F}$.
	
	\paragraph{Claim}: Player 0 wins the game $G_\mathcal{F}$.
	
	We first describe the strategy $\sigma$ for player 0 and show that it is winning afterwards. Let $x_i$, $y_j$, and $y_k$ be the variables of the last turn and let $S_{y_j} = \{z_0, \dots, z_h\} \subseteq Y$ be the set of grand-children of $y_j$ (then $y_k = z_a$ for some $a$). Player 0 then picks $z_b$ for $b = a+1 \text{ mod } h+1$.
	
	Let $\pi = t_0 t_1 \dots$ be a $\sigma$-play let $I \subseteq C$ be the set of infinitely occurring colors in $\pi$. From some point on, there is a node $y_{\max}$ such that the rest of the play remains in the subtree below that node and $y_{\max}$ itself is picked infinitely often by player 1. Let $\{z_1, \dots, z_h\}$ be the grand-children of $y_{\max}$. Since $\pi$ is a $\sigma$-play, for each $z_i$ there is a leaf below that node that is picked infinitely often by player 0. Therefore, $I \cap C_{z_i} \neq \emptyset$ and $I \cap C_{y_{\max}} \setminus C_{z_i} \neq \emptyset$ for all $i$, because of the two choices of player 1. That also means $I \not\subseteq C_{z_i}$ for all $i$.
	
	Finally, because the infinite play remains in the subtree of $y_{\max}$, we have $I \subseteq C_{y_{\max}}$. By definition of the split tree, we can deduce that $\pi$ is winning for player 0 (because $y_{\max}$ is a 0-node).
	
	\paragraph{Claim}: Winning strategies require at least $m^0_\mathcal{F}$ memory.
	
	Let $\mathcal{M}$ be a strategy automaton for player 0 with $|M| < m^0_\mathcal{F}$. Since there are $m^0_\mathcal{F}$ leaves in $\mathcal{S}'$, there is an $i$ such that player 0 never chooses $x_i$. Let $C_1 D_1 C_2 D_2 \dots C_n D_n (C_{n+1})$ (with $C_1 = C$) be the labels of the nodes on the path from the root to $x_i$. For every $x_j \neq x_i$, let $m(j) \in \{1, \dots, n\}$ be the index in that sequence of the lowest common ancestor of $x_i$ and $x_j$.
	
	The strategy $\tau$ for player 1 that we use works as follows: player 1 keeps track of a vector $\overline{d} = (d_1, \dots, d_n) \in D_1 \times \dots \times D_n$. Let $x_j$ be the choice of player 0 in a turn. First, player 1 picks the node labeled by $C_{m(j)}$. The first color pick $c \in C_{m(j)}$ will be $d_{m(j)} \in D_{m(j)} \subseteq C_{m(j)}$. Afterwards, the vector $\overline{d}$ is updated at component $m(j)$ to use the next element in $D_{m(j)}$ in some circular order. Let $E \subseteq C$ be the color label of the child of $C_{m(j)}$ towards $x_j$. The second color picked $c' \in C_{m(j)} \setminus E$ is an arbitrary color in the set $(C_{m(j)} \setminus E) \cap D_{m(j)}$. Together, these two choices imply that $\{c,c'\} \subseteq D_{m(j)}$.
	
	Let $\pi$ be the $\sigma_\mathcal{M}$-$\tau$-play with $I$ as the set of infinitely occurring colors. Let $1 \leq k \leq n$ be minimal such that player 1 chooses $C_k$ infinitely often in $\pi$. As we saw before, this means that $I \subseteq D_k$. Further, the strategy $\tau$ ensures that all successors of $D_k$ are picked infinitely often. Hence, $I = D_k \notin \mathcal{F}$.
\end{proof}

\vspace{0.5cm}
\begin{theorem}
	Muller games can be reduced to parity games with memory $l_\mathcal{F}$.
\end{theorem}
% no proof

\subsubsection{Split Trees}
\begin{definition}
	Let $\mathcal{F} \subseteq 2^C$. We write $\mathcal{F}|_D = \mathcal{F} \cap 2^D$ for all $D \subseteq C$. The \textbf{split tree} of $\mathcal{F}$ is called $\mathcal{S}_\mathcal{F}$ and is defined as follows: 
	\begin{itemize}
		\item Nodes in the tree are labeled by $2^C \times \{0,1\}$.
		\item If $C \in \mathcal{F}$, the root is labeled $(C, 0)$. Otherwise, the root is labeled $(C, 1)$.
		\item For every $\subseteq$-maximal set $D$ with $D \notin \mathcal{F}$, the root has the subtree $\mathcal{S}_{\mathcal{F}|_D}$ as a child.
	\end{itemize}
\end{definition}

\begin{definition}
	Let $\mathcal{F} \subseteq 2^C$. Let $\mathcal{F}_1, \dots, \mathcal{F}_n \subseteq 2^C$ such that $\mathcal{S}_{\mathcal{F}_1}, \dots, \mathcal{S}_{\mathcal{F}_n}$ are the direct subtrees of the root in $\mathcal{S}_\mathcal{F}$. We define the \textbf{memory number} 
	$$m_i(\mathcal{S}_\mathcal{F}) = \begin{cases}
		1 & \text{if } n = 0 \\
		\max_j m_i(S_{\mathcal{F}_j}) & \text{if the root is } (C, 1-i) \\
		\sum_j m_i(S_{\mathcal{F}_j}) & \text{if the root is } (C, i) 
	\end{cases}.$$
	
	For a short form, we write $m^i_\mathcal{F} = m_i(\mathcal{S}_\mathcal{F})$.
	
	We write $l_\mathcal{F} \in \mathbb{N}$ for the number of leaves in $\mathcal{S}_\mathcal{F}$.
\end{definition}

\begin{theorem}
\begin{itemize}
	\item $m^0_\mathcal{F} = m^1_{\mathcal{F}^\complement}$
	\item $m^i_\mathcal{F} \leq l_\mathcal{F}$
	\item $l_\mathcal{F} \leq |C|!$
\end{itemize}
\end{theorem}
% no proof

\vspace{1.5cm}
\subsection{Rabin \& Streett Games}
$\Omega = \{(E_i, F_i) \mid 1 \leq i \leq n\} \subseteq C \times C$ and \\
$\text{Win} = \{ \alpha \in C^\omega \mid \exists i: \text{Inf}(\alpha) \cap E_i = \emptyset \land \text{Inf}(\alpha) \cap F_i \neq \emptyset \}$ (Rabin) \\
$\text{Win} = \{ \alpha \in C^\omega \mid \forall i: \text{Inf}(\alpha) \cap E_i \neq \emptyset \lor \text{Inf}(\alpha) \cap F_i = \emptyset \}$ (Streett).

\begin{theorem}
	Rabin and Streett games are determined. In a Rabin game, player 0 has a uniform positional winning strategy from their winning region. In a Streett game, player 1 has a uniform positional winning strategy from their winning region. 
	
	For every $n$, there is a game graph $G_n$ and a condition $\Omega_n$ with $|\Omega_n| = n$ such that the opposite player requires memory $n!$ for a winning strategy from their winning region.
\end{theorem}
\begin{proof}
	Assume that $E_i \cap F_i = \emptyset$ for all $i$ and also that $E_i \neq \emptyset$. Consider the split tree $\mathcal{S}_\Omega$ of a Rabin-Streett game $(G, \Omega)$. The root is $(C, 1)$ with children $(C \setminus E_i, 0)$ for all $i$, each of which have as child the subtree $\mathcal{S}_{\Omega \setminus \{(E_i, F_i)\}}$. By induction, the memory number of these is $m_{\Omega \setminus \{(E_i, F_i)\}}^0 = 1$ and $m_{\Omega \setminus \{(E_i, F_i)\}}^1 = (n-1)!$. This gives $m^0_\Omega = 1$ and $m^1_\Omega = n!$.
\end{proof}

\vspace{1.5cm}
\subsection{Logic Games}
Let $\mathcal{L}$ be a logic and $\varphi \in \mathcal{L}$. Then $\text{Win}_\varphi = \{ \alpha \in C^\omega \mid \alpha \models \varphi \}$.

\begin{theorem}
	For $\mathcal{L} = \text{LTL}$, logic games are uniformly positionally determined and the winning strategies can be computed in $2^{2^{|\varphi|}}$.
\end{theorem}
\begin{proof}
	One can compute an NBA for $\varphi$ in exponential time which can then be transformed to a DPA.
\end{proof}

\begin{theorem}
	For $\mathcal{L} = \text{S1S}$, logic games are uniformly positionally determined and the winning strategies can be computed in $2 \uparrow |\varphi|$.
\end{theorem}
\begin{proof}
	One can compute an NBA for $\varphi$ in non-elementary time which can then be transformed to a DPA.
\end{proof}

\subsubsection{Church Synthesis}
Goal: given a specification $\varphi(\alpha, \beta)$, construct a function/program $f$ such that $f(\alpha) = \beta $ iff $\models~\varphi(\alpha, \beta)$.

Define a game $(G, \text{Win}_\varphi)$ where $G$ defines a game in which player 0 and player 1 alternatingly choose bits 0 or 1. By using the previous results, the game can be solved. A winning strategy for player 0 can be used as a program $f$.

\end{document}
















